{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# List of semesters you want to scrape\n",
    "semesters = [f\"{year}-{year+1}\" for year in range(2013, 2024)]\n",
    "\n",
    "# List of course numbers you're interested in\n",
    "course_numbers = [\"01005\"]  # Add more course numbers as needed\n",
    "\n",
    "# Base URL structure\n",
    "base_url = \"https://kurser.dtu.dk/course/\"\n",
    "\n",
    "# Function to fetch course table information\n",
    "def fetch_course_table(semester, course_number):\n",
    "    url = f\"{base_url}{semester}/{course_number}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find the table with the specific style\n",
    "        table = soup.find(\"table\", {\"style\": \"table-layout:fixed\"})\n",
    "        if table:\n",
    "            # Extract table rows and columns\n",
    "            rows = table.find_all(\"tr\")\n",
    "            table_data = []\n",
    "            for row in rows:\n",
    "                cols = row.find_all(\"td\")\n",
    "                cols = [col.get_text(strip=True) for col in cols]\n",
    "                table_data.append(cols)\n",
    "            return table_data\n",
    "        else:\n",
    "            return \"No table found.\"\n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"Timeout occurred\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Request failed: {e}\"\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "all_courses_data = []\n",
    "\n",
    "# Loop over each semester and course number\n",
    "for semester in semesters:\n",
    "    for course_number in course_numbers:\n",
    "        print(f\"Fetching table data for course {course_number} in semester {semester}\")\n",
    "        table_data = fetch_course_table(semester, course_number)\n",
    "        if isinstance(table_data, list):  # Ensure we got table data back\n",
    "            # Include semester and course number in each row\n",
    "            for row in table_data:\n",
    "                all_courses_data.append([semester, course_number] + row)\n",
    "        else:\n",
    "            print(table_data)  # Print any error messages\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(all_courses_data, columns=[\"Semester\", \"Course Number\", \"Column1\", \"Column2\", \"Column3\"])  # Adjust column names as needed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"dtu_courses_table.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data fetching complete. Results saved to dtu_courses_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://kurser.dtu.dk/course/2021-2022/01005'\n",
    "headers = {'User-Agent' : 'Clara'}\n",
    "response = requests.get(url, headers=headers, timeout=5, verify=False)\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def fetch_all_text_with_selenium(semester, course_number):\n",
    "    driver = webdriver.Chrome()  # Simple instantiation without custom path or options\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://kurser.dtu.dk/course/{semester}/{course_number}\"\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Optional: Scroll to the bottom of the page to trigger loading if needed\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Give it a moment to load\n",
    "        \n",
    "        # Get the page source and parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        # Get all text from the page\n",
    "        all_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "        return all_text\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def save_text_to_csv(text_data, filename=\"course_info.csv\"):\n",
    "    # Split the text data by lines\n",
    "    lines = text_data.split(\"\\n\")\n",
    "    \n",
    "    # Write data to a CSV file\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write each line as a row in the CSV file\n",
    "        for line in lines:\n",
    "            writer.writerow([line])\n",
    "\n",
    "# Example usage\n",
    "semester = \"2013-2014\"\n",
    "course_number = \"01005\"\n",
    "page_text = fetch_all_text_with_selenium(semester, course_number)\n",
    "print(page_text)\n",
    "\n",
    "# Save the extracted text to a CSV file\n",
    "save_text_to_csv(page_text, filename=\"course_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def fetch_all_text_with_selenium(semester, course_number):\n",
    "    options = Options()\n",
    "    options.headless = True  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://kurser.dtu.dk/course/{semester}/{course_number}\"\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Optional: Scroll to the bottom of the page to trigger loading if needed\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Give it a moment to load\n",
    "        \n",
    "        # Get the page source and parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        # Get all text from the page\n",
    "        all_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "        return all_text\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def save_text_to_csv(semester, course_number, text_data, filename=\"course_info.csv\"):\n",
    "    # Split the text data by lines\n",
    "    lines = text_data.split(\"\\n\")\n",
    "    \n",
    "    # Write data to a CSV file\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:  # Use 'a' mode to append to the file\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write semester, course number, and each line of the text as a row in the CSV file\n",
    "        for line in lines:\n",
    "            writer.writerow([semester, course_number, line])\n",
    "\n",
    "# List of semesters from 2013-2014 to 2023-2024\n",
    "semesters = [f\"{year}-{year+1}\" for year in range(2013, 2024)]\n",
    "\n",
    "# Example usage with multiple semesters\n",
    "course_number = \"01005\"\n",
    "\n",
    "# Clear the CSV file if it exists\n",
    "with open(\"course_info.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Semester\", \"Course Number\", \"Text\"])\n",
    "\n",
    "# Loop through each semester and scrape data\n",
    "for semester in semesters:\n",
    "    page_text = fetch_all_text_with_selenium(semester, course_number)\n",
    "    print(f\"Fetched data for {semester} - {course_number}\")\n",
    "    \n",
    "    # Save the extracted text to a CSV file\n",
    "    save_text_to_csv(semester, course_number, page_text, filename=\"course_info.csv\")\n",
    "\n",
    "print(\"Data fetching complete. Results saved to course_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def fetch_all_text_with_selenium(driver, semester, course_number):\n",
    "    url = f\"https://kurser.dtu.dk/course/{semester}/{course_number}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Optional: Scroll to the bottom of the page to trigger loading if needed\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)  # Give it a moment to load\n",
    "    \n",
    "    # Get the page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Get all text from the page\n",
    "    all_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return all_text\n",
    "\n",
    "def save_text_to_csv(semester, course_number, text_data, filename=\"course_info.csv\"):\n",
    "    # Split the text data by lines\n",
    "    lines = text_data.split(\"\\n\")\n",
    "    \n",
    "    # Write data to a CSV file\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:  # Use 'a' mode to append to the file\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write semester, course number, and each line of the text as a row in the CSV file\n",
    "        for line in lines:\n",
    "            writer.writerow([semester, course_number, line])\n",
    "\n",
    "# List of semesters from 2013-2014 to 2023-2024\n",
    "semesters = [f\"{year}-{year+1}\" for year in range(2017, 2024)]\n",
    "\n",
    "# Example usage with multiple semesters\n",
    "course_number = \"01005\"\n",
    "\n",
    "# Clear the CSV file if it exists\n",
    "with open(\"course_info.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Semester\", \"Course Number\", \"Text\"])\n",
    "\n",
    "# Start the browser session once\n",
    "driver = webdriver.Chrome()  # Simple instantiation without custom path or options\n",
    "\n",
    "try:\n",
    "    # Loop through each semester and scrape data\n",
    "    for semester in semesters:\n",
    "        page_text = fetch_all_text_with_selenium(driver, semester, course_number)\n",
    "        print(f\"Fetched data for {semester} - {course_number}\")\n",
    "        \n",
    "        # Save the extracted text to a CSV file\n",
    "        save_text_to_csv(semester, course_number, page_text, filename=\"course_info.csv\")\n",
    "finally:\n",
    "    # Close the browser session when done\n",
    "    driver.quit()\n",
    "\n",
    "print(\"Data fetching complete. Results saved to course_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def fetch_all_text_with_selenium(driver, semester, course_number):\n",
    "    url = f\"https://kurser.dtu.dk/course/{semester}/{course_number}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(2)  # Give it a moment to load\n",
    "    \n",
    "    # Get the page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Get all text from the page\n",
    "    all_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return all_text\n",
    "\n",
    "def save_text_to_csv(semester, course_number, text_data, filename=\"course_info.csv\"):\n",
    "    # Split the text data by lines\n",
    "    lines = text_data.split(\"\\n\")\n",
    "    \n",
    "    # Write data to a CSV file\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:  # Use 'a' mode to append to the file\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write semester, course number, and each line of the text as a row in the CSV file\n",
    "        for line in lines:\n",
    "            writer.writerow([semester, course_number, line])\n",
    "\n",
    "# List of semesters from 2017-2018 to 2023-2024\n",
    "semesters = [f\"{year}-{year+1}\" for year in range(2017, 2024)]\n",
    "\n",
    "# Generate course numbers from 01005 to 88717\n",
    "course_numbers = [str(num).zfill(5) for num in range(1005, 88718)]\n",
    "\n",
    "# Clear the CSV file if it exists\n",
    "with open(\"course_info.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Semester\", \"Course Number\", \"Text\"])\n",
    "\n",
    "# Start the browser session once\n",
    "driver = webdriver.Chrome()  # Simple instantiation without custom path or options\n",
    "\n",
    "try:\n",
    "    # Loop through each semester and scrape data\n",
    "    for semester in semesters:\n",
    "        page_text = fetch_all_text_with_selenium(driver, semester, course_number)\n",
    "        print(f\"Fetched data for {semester} - {course_number}\")\n",
    "        \n",
    "        # Save the extracted text to a CSV file\n",
    "        save_text_to_csv(semester, course_number, page_text, filename=\"course_info.csv\")\n",
    "finally:\n",
    "    # Close the browser session when done\n",
    "    driver.quit()\n",
    "\n",
    "print(\"Data fetching complete. Results saved to course_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def fetch_kursusinformation_with_selenium(driver, semester, course_number):\n",
    "    url = f\"https://kurser.dtu.dk/course/{semester}/{course_number}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(2)  # Give it a moment to load fully if necessary\n",
    "    \n",
    "    # Get the page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Find the specific \"Kursusinformation\" table or section within the div\n",
    "    kursusinformation_section = soup.select_one(\"div.box.information\")\n",
    "    \n",
    "    if kursusinformation_section:\n",
    "        # Extract all the text within the Kursusinformation section\n",
    "        kursusinformation_text = kursusinformation_section.get_text(separator=\"\\n\", strip=True)\n",
    "        return kursusinformation_text\n",
    "    else:\n",
    "        return \"No Kursusinformation found\"\n",
    "\n",
    "def save_kursusinformation_to_csv(semester, course_number, kursusinformation_text, filename=\"kursusinformation.csv\"):\n",
    "    # Write Kursusinformation data to a CSV file\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:  # Use 'a' mode to append to the file\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header only if the file is empty\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow([\"Semester\", \"Course Number\", \"Kursusinformation\"])\n",
    "        \n",
    "        # Write the Kursusinformation with the semester and course number\n",
    "        writer.writerow([semester, course_number, kursusinformation_text])\n",
    "\n",
    "# List of semesters from 2017-2018 to 2023-2024\n",
    "semesters = [f\"{year}-{year+1}\" for year in range(2017, 2024)]\n",
    "\n",
    "# Generate course numbers from 01005 to 88717\n",
    "course_number = \"01005\"\n",
    "#course_numbers = [str(num).zfill(5) for num in range(01001, 88718)]\n",
    "#course_numbers = [str(num).zfill(5) for num in range(0, 20000) if str(num).startswith(\"0\")]\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Optional: Start maximized\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "\n",
    "# Start the browser session once\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Loop through each semester and course number and scrape data\n",
    "    for semester in semesters:\n",
    "        for course_number in course_numbers:\n",
    "            kursusinformation_text = fetch_kursusinformation_with_selenium(driver, semester, course_number)\n",
    "            if kursusinformation_text:\n",
    "                print(f\"Fetched Kursusinformation for {semester} - {course_number}\")\n",
    "                # Save the extracted Kursusinformation to a CSV file\n",
    "                save_kursusinformation_to_csv(semester, course_number, kursusinformation_text, filename=\"kursusinformation.csv\")\n",
    "            else:\n",
    "                print(f\"No Kursusinformation found for {semester} - {course_number}\")\n",
    "finally:\n",
    "    # Close the browser session when done\n",
    "    driver.quit()\n",
    "\n",
    "print(\"Data fetching complete. Results saved to kursusinformation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched Kursusinformation for 2017-2018 - 01000\n",
      "Fetched Kursusinformation for 2017-2018 - 01001\n",
      "Fetched Kursusinformation for 2017-2018 - 01002\n",
      "Fetched Kursusinformation for 2017-2018 - 01003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b7/xr_h9h1s35l0rntn_yj3w_9h0000gn/T/ipykernel_7189/1894866217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msemester\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msemesters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcourse_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcourse_numbers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mkursusinformation_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_kursusinformation_with_selenium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcourse_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkursusinformation_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fetched Kursusinformation for {semester} - {course_number}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/b7/xr_h9h1s35l0rntn_yj3w_9h0000gn/T/ipykernel_7189/1894866217.py\u001b[0m in \u001b[0;36mfetch_kursusinformation_with_selenium\u001b[0;34m(driver, semester, course_number)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Give it a moment to load fully if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Get the page source and parse with BeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def fetch_kursusinformation_with_selenium(driver, semester, course_number):\n",
    "    url = f\"https://kurser.dtu.dk/course/{semester}/{course_number}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(2)  # Give it a moment to load fully if necessary\n",
    "    \n",
    "    # Get the page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Find the specific \"Kursusinformation\" table or section within the div\n",
    "    kursusinformation_section = soup.select_one(\"div.box.information\")\n",
    "    \n",
    "    if kursusinformation_section:\n",
    "        # Extract all the text within the Kursusinformation section\n",
    "        kursusinformation_text = kursusinformation_section.get_text(separator=\"\\n\", strip=True)\n",
    "        return kursusinformation_text\n",
    "    else:\n",
    "        return \"No Kursusinformation found\"\n",
    "\n",
    "def save_kursusinformation_to_csv(semester, course_number, kursusinformation_text, filename=\"kursusinformation.csv\"):\n",
    "    # Write Kursusinformation data to a CSV file\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:  # Use 'a' mode to append to the file\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header only if the file is empty\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow([\"Semester\", \"Course Number\", \"Kursusinformation\"])\n",
    "        \n",
    "        # Write the Kursusinformation with the semester and course number\n",
    "        writer.writerow([semester, course_number, kursusinformation_text])\n",
    "\n",
    "# List of semesters from 2017-2018 to 2023-2024\n",
    "semesters = [f\"{year}-{year+1}\" for year in range(2017, 2024)]\n",
    "\n",
    "# Generate course numbers from 01005 to 88717\n",
    "course_number = \"01005\"\n",
    "#course_numbers = [str(num).zfill(5) for num in range(01001, 88718)]\n",
    "#course_numbers = [str(num).zfill(5) for num in range(0, 20000) if str(num).startswith(\"0\")]\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Optional: Start maximized\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "\n",
    "# Start the browser session once\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Loop through each semester and course number and scrape data\n",
    "    for semester in semesters:\n",
    "        for course_number in course_numbers:\n",
    "            kursusinformation_text = fetch_kursusinformation_with_selenium(driver, semester, course_number)\n",
    "            if kursusinformation_text:\n",
    "                print(f\"Fetched Kursusinformation for {semester} - {course_number}\")\n",
    "                # Save the extracted Kursusinformation to a CSV file\n",
    "                save_kursusinformation_to_csv(semester, course_number, kursusinformation_text, filename=\"kursusinformation.csv\")\n",
    "finally:\n",
    "    # Close the browser session when done\n",
    "    driver.quit()\n",
    "\n",
    "print(\"Data fetching complete. Results saved to kursusinformation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched Kursusinformation for 2017-2018 - 01005\n",
      "Fetched Kursusinformation for 2018-2019 - 01005\n",
      "Fetched Kursusinformation for 2019-2020 - 01005\n",
      "Fetched Kursusinformation for 2020-2021 - 01005\n",
      "Fetched Kursusinformation for 2021-2022 - 01005\n",
      "Fetched Kursusinformation for 2022-2023 - 01005\n",
      "Fetched Kursusinformation for 2023-2024 - 01005\n",
      "Data fetching complete. Results saved to kursusinformation.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def fetch_kursusinformation_with_selenium(driver, semester, course_number):\n",
    "    url = f\"https://kurser.dtu.dk/course/{semester}/{course_number}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(2)  # Give it a moment to load fully if necessary\n",
    "    \n",
    "    # Get the page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Find the specific \"Kursusinformation\" table or section within the div\n",
    "    kursusinformation_section = soup.select_one(\"div.box.information\")\n",
    "    \n",
    "    if kursusinformation_section:\n",
    "        # Extract all the text within the Kursusinformation section\n",
    "        kursusinformation_text = kursusinformation_section.get_text(separator=\"\\n\", strip=True)\n",
    "        return kursusinformation_text\n",
    "    else:\n",
    "        return \"No Kursusinformation found\"\n",
    "\n",
    "def save_kursusinformation_to_csv(semester, course_number, kursusinformation_text, filename=\"kursusinformation.csv\"):\n",
    "    # Write Kursusinformation data to a CSV file\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:  # Use 'a' mode to append to the file\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header only if the file is empty\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow([\"Semester\", \"Course Number\", \"Kursusinformation\"])\n",
    "        \n",
    "        # Write the Kursusinformation with the semester and course number\n",
    "        writer.writerow([semester, course_number, kursusinformation_text])\n",
    "\n",
    "# List of semesters from 2017-2018 to 2023-2024\n",
    "semesters = [f\"{year}-{year+1}\" for year in range(2017, 2024)]\n",
    "\n",
    "# Specific course number to fetch\n",
    "course_number = \"01005\"\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Optional: Start maximized\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "\n",
    "# Start the browser session once\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Loop through each semester and scrape data for the specific course number\n",
    "    for semester in semesters:\n",
    "        kursusinformation_text = fetch_kursusinformation_with_selenium(driver, semester, course_number)\n",
    "        if kursusinformation_text:\n",
    "            print(f\"Fetched Kursusinformation for {semester} - {course_number}\")\n",
    "            # Save the extracted Kursusinformation to a CSV file\n",
    "            save_kursusinformation_to_csv(semester, course_number, kursusinformation_text, filename=\"kursusinformation.csv\")\n",
    "finally:\n",
    "    # Close the browser session when done\n",
    "    driver.quit()\n",
    "\n",
    "print(\"Data fetching complete. Results saved to kursusinformation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
